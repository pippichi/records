# Qwen+RAG

參考：

https://blog.csdn.net/Python_0011/article/details/139752344（大模型RAG入门及实践（非常详细）零基础入门到精通，收藏这一篇就够了）

https://blog.csdn.net/qq_52943402/article/details/137970846（Qwen+langchain使用流程）

https://zhuanlan.zhihu.com/p/668931562（Qwen 本地部署与 LangChain 应用开发全攻略）

# langchain

參考：

https://python.langchain.com

## 文本特征提取

參考：

https://python.langchain.com/v0.1/docs/use_cases/extraction/quickstart（Extracting structured output）

# 向量数据库

參考：

https://blog.csdn.net/xzq_qzx_/article/details/136535125（Chroma向量数据库使用案例）

# 文本语义表征(Sentence-Bert、Simcse)

参考：

https://blog.csdn.net/qq_40176087/article/details/125471765（文本语义表征(Sentence-Bert、Simcse)的应用和实践）

https://zhuanlan.zhihu.com/p/659682364（Sentence-BERT（SBERT）模型介绍及Sentence Transformers库的使用）

https://blog.csdn.net/weixin_43922901/article/details/106014964（语义相似度、句向量生成超强模型之SBERT《Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks》）

# vllm（部署大模型）

參考：

https://docs.vllm.ai/en/latest/getting_started/installation.html#（vllm官方网站）

https://zhuanlan.zhihu.com/p/691824083（部署vLLM:分步指南）

https://zhuanlan.zhihu.com/p/706432104（VLLM 部署的一些细节，关于CUDA对应版本的问题）

# Ollama大模型管理器

參考：

https://blog.csdn.net/python122_/article/details/140945720（Ollama完整教程：本地LLM管理、WebUI对话、Python/Java客户端API应用）

# LLaMA-Factory（微调模型）

参考：

https://blog.csdn.net/weixin_48007632/article/details/138819599（AI智能体研发之路-模型篇（一）：大模型训练框架LLaMA-Factory在国内网络环境下的安装、部署及使用）

https://zhuanlan.zhihu.com/p/714254915（LLaMA-Factory + vllm）

# 大模型网站

https://www.modelscope.cn/my/overview（modelscope魔塔社区）

https://hf-mirror.com/（huggingface.co镜像域名）

https://smith.langchain.com/（langchain）

https://huggingface.co/（huggingface.co，需要翻墙）

# deepspeed

分布式训练、推理

参考：

https://www.deepspeed.ai/getting-started/

# flash-attention

参考：

https://blog.csdn.net/qq_25038325/article/details/133990240（qwen大模型，推理速度慢，单卡/双卡速度慢，flash-attention安装，解决方案★）

https://blog.csdn.net/qq_21491605/article/details/136109125（Windows环境下flash-attention安装）



